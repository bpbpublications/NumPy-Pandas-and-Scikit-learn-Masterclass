{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Price Regression ðŸ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Custom imports\n",
    "from regress.missing_values import missing_values_summarizer\n",
    "from regress.styler import style_dataframe\n",
    "from regress.metrics import compute_metrics\n",
    "#https://www.kaggle.com/datasets/yasserh/housing-prices-dataset/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_dataframe(train.describe(include=['int', 'float']))\n",
    "len(train.describe(include=['int', 'float']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_dataframe(train.describe(include=['object']))\n",
    "len(train.describe(include=['object']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_correlation(df, x_col, \n",
    "                        y_col, \n",
    "                        title=None, \n",
    "                        size=8, line_color='red'):\n",
    " \n",
    "\n",
    "    if x_col not in df.columns or y_col not in df.columns:\n",
    "        raise ValueError(f\"Columns '{x_col}' or '{y_col}' not found in DataFrame\")\n",
    "    \n",
    "    if not pd.api.types.is_numeric_dtype(df[x_col]) or not pd.api.types.is_numeric_dtype(df[y_col]):\n",
    "        raise ValueError(\"Both x_col and y_col must be numeric\")\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "\n",
    "    sns.regplot(\n",
    "        x=df[x_col],\n",
    "        y=df[y_col],\n",
    "        scatter_kws={'s': size},  \n",
    "        line_kws={'color': line_color},  \n",
    "        ci=None \n",
    "    )\n",
    "\n",
    "    plt.xlabel(x_col)\n",
    "    plt.ylabel(y_col)\n",
    "    plt.title(title if title else f\"{y_col} vs {x_col}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_correlation(df=train, \n",
    "                    x_col=\"LotFrontage\", \n",
    "                    y_col=\"SalePrice\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop unecessary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=['Id', 'SalePrice'])\n",
    "y_train = train['SalePrice'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "props_df, _ = missing_values_summarizer(df=X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_dataframe(props_df.iloc[np.where(props_df['missing_count'] > 0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_data(X_train, X_test, X_val=None, \n",
    "                    threshold=0.7):\n",
    "    \n",
    "    numeric_cols = X_train.select_dtypes(include=['number']).columns.tolist()\n",
    "    categorical_cols = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    min_non_na = int(threshold * len(X_train))\n",
    "    new_numeric_cols = X_train[numeric_cols].dropna(axis=1, \n",
    "                                                    thresh=min_non_na).columns.tolist()\n",
    "    new_categorical_cols = X_train[categorical_cols].dropna(axis=1, \n",
    "                                                            thresh=min_non_na).columns.tolist()\n",
    "\n",
    "    numeric_pipeline = Pipeline([\n",
    "        ('numeric_imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', RobustScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_pipeline = Pipeline([\n",
    "        ('categorical_imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('one_hot_encoder', OneHotEncoder(handle_unknown='ignore', \n",
    "                                          sparse_output=False, drop='first'))\n",
    "    ])\n",
    "\n",
    "    preprocessing_pipeline = ColumnTransformer([\n",
    "        ('numeric_preprocess', numeric_pipeline, \n",
    "         new_numeric_cols),\n",
    "        ('categorical_preprocess', categorical_pipeline, \n",
    "         new_categorical_cols)\n",
    "    ], remainder='drop', \n",
    "    verbose_feature_names_out=False)\n",
    "\n",
    "    X_train_transformed = preprocessing_pipeline.fit_transform(X_train)\n",
    "    X_test_transformed = preprocessing_pipeline.transform(X_test)\n",
    "\n",
    "    feature_names = preprocessing_pipeline.get_feature_names_out()\n",
    "    X_train_df = pd.DataFrame(X_train_transformed, \n",
    "                              columns=feature_names, \n",
    "                              index=X_train.index)\n",
    "    X_test_df = pd.DataFrame(X_test_transformed, \n",
    "                             columns=feature_names, \n",
    "                             index=X_test.index)\n",
    "\n",
    "    if X_val is not None:\n",
    "        X_val_transformed = preprocessing_pipeline.transform(X_val)\n",
    "        X_val_df = pd.DataFrame(X_val_transformed, \n",
    "                                columns=feature_names, \n",
    "                                index=X_val.index)\n",
    "    else:\n",
    "        X_val_df = None\n",
    "\n",
    "    def align_columns(*dfs):\n",
    "        all_columns = list(set().union(*(df.columns for df in dfs if df is not None)))\n",
    "        for df in dfs:\n",
    "            if df is not None:\n",
    "                missing_cols = [col for col in all_columns if col not in df.columns]\n",
    "                for col in missing_cols:\n",
    "                    df[col] = 0\n",
    "                df = df[all_columns]  \n",
    "        return dfs\n",
    "\n",
    "    X_train_df, X_test_df, X_val_df = align_columns(X_train_df, \n",
    "                                                    X_test_df, \n",
    "                                                    X_val_df)\n",
    "\n",
    "    return (X_train_df, X_test_df, X_val_df) if X_val is not None else (X_train_df, X_test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pp, X_test_pp = preprocess_data(X_train=X_train, \n",
    "                                        X_test=test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"linear_regression\": LinearRegression(),\n",
    "    \"ridge\": Ridge(alpha=1.0),\n",
    "    \"elastic_net\": ElasticNet(alpha=0.1, \n",
    "                              l1_ratio=0.5),\n",
    "    \"random_forest\": RandomForestRegressor(n_estimators=100, \n",
    "                                           random_state=42),\n",
    "    \"xgboost\": XGBRegressor(n_estimators=500, \n",
    "                            max_depth=6, \n",
    "                            learning_rate=0.1, \n",
    "                            random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def regression_training_loop(models, \n",
    "                             X_train, \n",
    "                             y_train, \n",
    "                             X_val=None, \n",
    "                             save_path='models', \n",
    "                             use_best_model=True, \n",
    "                             cv_folds=5,\n",
    "                             scoring_metric=\"MSE\"):\n",
    "    \n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    results = {}\n",
    "    best_model = None \n",
    "    best_score = float('-inf') if scoring_metric == 'R2' else float(\"inf\")  \n",
    "    kf = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(f'\\nTraining {name} with {cv_folds}-Fold Cross Validation...')\n",
    "        \n",
    "        fold_metrics = []  \n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X_train), 1):\n",
    "            print(f\"  â³ Training {name} - Fold {fold}/{cv_folds}...\")\n",
    "\n",
    "            X_train_cv, X_val_cv = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "            y_train_cv, y_val_cv = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "            model.fit(X_train_cv, y_train_cv)\n",
    "            y_pred_cv = model.predict(X_val_cv)\n",
    "\n",
    "            metrics = compute_metrics(y_val_cv, y_pred_cv)\n",
    "            fold_metrics.append(metrics)\n",
    "\n",
    "            with open(os.path.join(save_path, f\"{name}-fold{fold}.sav\"), 'wb') as f:\n",
    "                pickle.dump(model, f)\n",
    "\n",
    "        avg_metrics = pd.DataFrame(fold_metrics).mean().to_dict()\n",
    "        results[name] = avg_metrics\n",
    "\n",
    "        metric_val = avg_metrics[scoring_metric]\n",
    "        if (scoring_metric == \"R2\" and metric_val > best_score) or (scoring_metric in [\"MSE\", \n",
    "                                                                                       \"RMSE\", \n",
    "                                                                                       \"MAE\", \n",
    "                                                                                       \"MSLE\"] \n",
    "                                                                                       and metric_val < best_score):\n",
    "            best_score = metric_val\n",
    "            best_model = model\n",
    "\n",
    "    results_df = pd.DataFrame(results).T\n",
    "    formatted_results = results_df.applymap(lambda x: f\"{x:,.2f}\" if isinstance(x, \n",
    "                                                                                (int, float)) else x)\n",
    "\n",
    "    print(\"\\nâœ… Model Training Completed. Results:\")\n",
    "    print(formatted_results)\n",
    "\n",
    "    if use_best_model and best_model:\n",
    "        print(f\"\\nðŸ† Retraining best model ({best_model.__class__.__name__}) on full training data...\")\n",
    "        best_model.fit(X_train, y_train)\n",
    "\n",
    "        best_model_filename = os.path.join(save_path, f\"best_model_{best_model.__class__.__name__}.sav\")\n",
    "        with open(best_model_filename, 'wb') as f:\n",
    "            pickle.dump(best_model, f)\n",
    "        \n",
    "        if X_val is not None: \n",
    "            print(\"\\nðŸ“Š Generating predictions on validation set...\")\n",
    "            val_preds = best_model.predict(X_val)\n",
    "            return best_model, formatted_results, val_preds\n",
    "\n",
    "    return best_model, formatted_results, best_model_filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model, model_results, df_best_model_fn = regression_training_loop(\n",
    "    models, \n",
    "    X_train=X_train_pp,\n",
    "    y_train=y_train,\n",
    "    scoring_metric=\"MAE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_dataframe(model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test final model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(df_best_model_fn, 'rb') as f:\n",
    "    best_model = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Shapley to visualise local and global importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_X_test = X_test_pp[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(best_model, sample_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer(sample_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, sample_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "shap.waterfall_plot(shap_values[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value, \n",
    "                shap_values[idx].values, \n",
    "                sample_X_test.iloc[idx], matplotlib=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join results on to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_preds = best_model.predict(X_test_pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_with_preds = pd.concat(\n",
    "    [\n",
    "        pd.Series(y_test_preds, name='PredSalePrice'), \n",
    "        X_test_pp\n",
    "    ], \n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_dataframe(x_test_with_preds.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scikit-learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
